{
 "metadata": {
  "name": "",
  "signature": "sha256:95d53b50a4deb03fed81ec0234c36826b7106377666cf10bfc857ce88fc3bd56"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classifiers -- All Alike, Yet Different"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "In this chapter we will continue our work from *chap_tutorial_mappers* in\n",
      "order to replicate the study of *Haxby et al. (2001)*. For this\n",
      "tutorial there is a little helper function to yield the dataset we generated\n",
      "manually before:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mvpa2.tutorial_suite import *\n",
      "ds = get_haxby2001_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "The original study employed a so-called 1-nearest-neighbor classifier, using\n",
      "correlation as a distance measure. In PyMVPA this type of classifier is\n",
      "provided by the [kNN](http://pymvpa.org/generated/mvpa2.clfs.knn.kNN.html#mvpa2-clfs-knn-knn) class, that makes it possible to specify\n",
      "the desired parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = kNN(k=1, dfx=one_minus_correlation, voting='majority')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "A k-Nearest-Neighbor classifier performs classification based on the similarity\n",
      "of a sample with respect to each sample in a [training dataset](http://pymvpa.org/glossary.html#term-training-dataset).  The\n",
      "value of `k` specifies the number of neighbors to derive a prediction,\n",
      "`dfx` sets the distance measure that determines the neighbors, and `voting`\n",
      "selects a strategy to choose a single label from the set of targets assigned to\n",
      "these neighbors."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- - -\n",
      "**Exercise**\n",
      "\n",
      "\n",
      "\n",
      "Access the built-in help to inspect the `kNN` class regarding additional\n",
      "configuration options."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kNN?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- - -\n",
      "\n",
      "\n",
      "Now that we have a classifier instance, it can be easily trained by passing the\n",
      "dataset to its `train()` method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.train(ds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "A trained classifier can subsequently be used to perform classification of\n",
      "unlabeled samples. The classification performance can be assessed by comparing\n",
      "these predictions to the target labels."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions = clf.predict(ds.samples)\n",
      "np.mean(predictions == ds.sa.targets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "We see that the classifier performs remarkably well on our dataset -- it\n",
      "doesn't make even a single prediction error. However, most of the time we would\n",
      "not be particularly interested in the prediction accuracy of a classifier on the\n",
      "same dataset that it got trained with."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- - -\n",
      "**Exercise**\n",
      "\n",
      "\n",
      "\n",
      "Think about why this particular classifier will always perform error-free\n",
      "classification of the training data -- regardless of the actual dataset\n",
      "content. If the reason is not immediately obvious, take a look at chapter\n",
      "13.3 in \n",
      "*The Elements of Statistical Learning*. Investigate how\n",
      "the accuracy varies with different values of `k`. Why is that?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# you can use this cell for this exercise"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- - -\n",
      "\n",
      "\n",
      "Instead, we are interested in the generalizability of the classifier on new,\n",
      "unseen data. This would allow us, in principle, to use it to assign labels to\n",
      "unlabeled data. Because we only have a single dataset, it needs to be split\n",
      "into (at least) two parts to achieve this. In the original study, Haxby and\n",
      "colleagues split the dataset into patterns of activations from odd versus\n",
      "even-numbered runs. Our dataset has this information in the `runtype` sample\n",
      "attribute:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print ds.sa.runtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['even' 'even' 'even' 'even' 'even' 'even' 'even' 'even' 'odd' 'odd' 'odd'\n",
        " 'odd' 'odd' 'odd' 'odd' 'odd']\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Using this attribute we can now easily split the dataset in half. PyMVPA\n",
      "datasets can be sliced in similar ways as [NumPy](http://numpy.scipy.org)'s `ndarray`. The following\n",
      "calls select the subset of samples (i.e. rows in the datasets) where the value\n",
      "of the `runtype` attribute is either the string 'even' or 'odd'."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds_split1 = ds[ds.sa.runtype == 'odd']\n",
      "len(ds_split1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "8"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds_split2 = ds[ds.sa.runtype == 'even']\n",
      "len(ds_split2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "8"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Now we could repeat the steps above: call `train()` with one dataset half\n",
      "and `predict()` with the other, and compute the prediction accuracy\n",
      "manually.  However, a more convenient way is to let the classifier do this for\n",
      "us.  Many objects in PyMVPA support a post-processing step that we can use to\n",
      "compute something from the actual results. The example below computes the\n",
      "*mismatch error* between the classifier predictions and the *target* values\n",
      "stored in our dataset. To make this work, we do not call the classifier's\n",
      "`predict()` method anymore, but \"call\" the classifier directly with the test\n",
      "dataset. This is a very common usage pattern in PyMVPA that we shall see a lot\n",
      "over the course of this tutorial.  Again, please note that we compute an error\n",
      "now, hence lower values represent more accurate classification."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.set_postproc(BinaryFxNode(mean_mismatch_error, 'targets'))\n",
      "clf.train(ds_split2)\n",
      "err = clf(ds_split1)\n",
      "print np.asscalar(err)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.125\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "In this case, our choice of which half of the dataset is used for training and\n",
      "which half for testing was completely arbitrary, hence we could also estimate\n",
      "the transfer error after swapping the roles:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.train(ds_split1)\n",
      "err = clf(ds_split2)\n",
      "print np.asscalar(err)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "We see that on average the classifier error is really low, and we achieve an\n",
      "accuracy level comparable to the results reported in the original study.\n",
      ".. _sec_tutorial_crossvalidation:"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Cross-validation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "What we have just done was to manually split the dataset into combinations of\n",
      "training and testing datasets, given a specific sample attribute -- in this\n",
      "case whether a *pattern of activation* or [sample](http://pymvpa.org/glossary.html#term-sample) came from *even* or\n",
      "*odd* runs.  We ran the classification analysis on each split to estimate the\n",
      "performance of the classifier model. In general, this approach is called\n",
      "[cross-validation](http://pymvpa.org/glossary.html#term-cross-validation), and involves splitting the dataset into multiple\n",
      "pairs of subsets, choosing sample groups by some criterion, and estimating the\n",
      "classifier performance by training it on the first dataset in a split and\n",
      "testing against the second dataset from the same split.\n",
      "\n",
      "PyMVPA provides a way to allow complete cross-validation procedures to run\n",
      "fully automatic, without the need for manual splitting of a dataset. Using the\n",
      "[CrossValidation](http://pymvpa.org/generated/mvpa2.measures.base.CrossValidation.html#mvpa2-measures-base-crossvalidation) class, a cross-validation is set up by\n",
      "specifying what measure should be computed on each dataset split and how\n",
      "dataset splits should be generated. The measure that is usually computed is the\n",
      "transfer error that we already looked at in the previous section. The second\n",
      "element, a [generator](http://pymvpa.org/glossary.html#term-generator) for datasets, is another very common tool in\n",
      "PyMVPA. The following example uses\n",
      "[HalfPartitioner](http://pymvpa.org/generated/mvpa2.generators.partition.HalfPartitioner.html#mvpa2-generators-partition-halfpartitioner), a generator that, when called\n",
      "with a dataset, marks all samples regarding their association with the first or\n",
      "second half of the dataset. This happens based on the values of a specified\n",
      "sample attribute -- in this case `runtype` -- much like the manual dataset\n",
      "splitting that we have performed earlier.\n",
      "[HalfPartitioner](http://pymvpa.org/generated/mvpa2.generators.partition.HalfPartitioner.html#mvpa2-generators-partition-halfpartitioner) will make sure to subsequently\n",
      "assign samples to both halves, i.e. samples from the first half in the first\n",
      "generated dataset will be in the second half of the second generated dataset.\n",
      "With these two techniques we can replicate our manual cross-validation easily\n",
      "-- reusing our existing classifier, but without the custom post-processing\n",
      "step."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.set_postproc(None)\n",
      "hpart = HalfPartitioner(attr='runtype')\n",
      "cv = CrossValidation(clf, hpart)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- - -\n",
      "**Exercise**\n",
      "\n",
      "\n",
      "\n",
      "Try calling the `hpart` object with our dataset. What happens? Now try\n",
      "passing the dataset to its `generate()` methods. What happens now?\n",
      "Make yourself familiar with the concept of a Python generator. Investigate\n",
      "what the code snippet `list(xrange(5))` does, and try to adapt it to the\n",
      "`HalfPartitioner`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list(hpart.generate(ds))[1].sa.partitions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 77,
       "text": [
        "array([1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2])"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- - -\n",
      "\n",
      "\n",
      "Once the `cv` object is created, it can be called with a dataset, just like\n",
      "we did with the classifier before. It will internally perform all the dataset\n",
      "partitioning, split each generated dataset into training and testing sets\n",
      "(based on the partitions), and train and test the classifier repeatedly.\n",
      "Finally, it will return the results of all cross-validation folds."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv_results = cv(ds)\n",
      "np.mean(cv_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 71,
       "text": [
        "0.0625"
       ]
      }
     ],
     "prompt_number": 71
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Actually, the cross-validation results are returned as another dataset that has\n",
      "one sample per fold and a single feature with the computed transfer-error per\n",
      "fold."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(cv_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 61,
       "text": [
        "2"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv_results.samples"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 62,
       "text": [
        "array([[ 0.   ],\n",
        "       [ 0.125]])"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Any classifier, really"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "A short summary of all code for the analysis we developed so far is this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = kNN(k=1, dfx=one_minus_correlation, voting='majority')\n",
      "cvte = CrossValidation(clf, HalfPartitioner(attr='runtype'))\n",
      "cv_results = cvte(ds)\n",
      "np.mean(cv_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 78,
       "text": [
        "0.0625"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Looking at this little code snippet we can nicely see the logical parts of\n",
      "a cross-validated classification analysis.\n",
      "\n",
      "1. Load the data\n",
      "\n",
      "2. Choose a classifier\n",
      "\n",
      "3. Set up an error function\n",
      "\n",
      "4. Evaluate the error in a cross-validation procedure\n",
      "\n",
      "5. Inspect results\n",
      "\n",
      "Our previous choice of the classifier was guided by the intention to replicate\n",
      "*Haxby et al. (2001)*, but what if we want to try a different\n",
      "algorithm? In this case another nice feature of PyMVPA comes into play. All\n",
      "classifiers implement a common interface that makes them easily interchangeable\n",
      "without the need to adapt any other part of the analysis code.  If, for\n",
      "example, we want to try the popular [None](http://pymvpa.org/generated/support vector machine.html#support vector machine) (SVM) on our example dataset it looks like this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = LinearCSVMC()\n",
      "cvte = CrossValidation(clf, HalfPartitioner(attr='runtype'))\n",
      "cv_results = cvte(ds)\n",
      "np.mean(cv_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 79,
       "text": [
        "0.1875"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Instead of k-nearest-neighbor, we create a linear SVM classifier,\n",
      "internally using the popular LIBSVM library (note that PyMVPA provides\n",
      "additional SVM implementations). The rest of the code remains identical.\n",
      "SVM with its default settings seems to perform slightly worse than the\n",
      "simple kNN-classifier. We'll get back to the classifiers shortly. Let's\n",
      "first look at the remaining part of this analysis.\n",
      "\n",
      "We already know that [CrossValidation](http://pymvpa.org/generated/mvpa2.measures.base.CrossValidation.html#mvpa2-measures-base-crossvalidation) can be used to\n",
      "compute errors. So far we have only used the mean number of mismatches between\n",
      "actual targets and classifier predictions as the error function (which is the\n",
      "default).  However, PyMVPA offers a number of alternative functions in the\n",
      "[None](http://pymvpa.org/generated/mvpa2.misc.errorfx.html#mvpa2-misc-errorfx) module, but it is also trivial to specify custom\n",
      "ones.  For example, if we do not want to have error reported, but instead\n",
      "accuracy, we can do that:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cvte = CrossValidation(clf, HalfPartitioner(attr='runtype'),\n",
      "                       errorfx=lambda p, t: np.mean(p == t))\n",
      "cv_results = cvte(ds)\n",
      "np.mean(cv_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 80,
       "text": [
        "0.8125"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "This example reuses the SVM classifier we have create before, and\n",
      "yields exactly what we expect from the previous result.\n",
      "\n",
      "The details of the cross-validation procedure are also heavily\n",
      "customizable. We have seen that a [Partitioner](http://pymvpa.org/generated/mvpa2.generators.partition.Partitioner.html#mvpa2-generators-partition-partitioner) is\n",
      "used to generate training and testing dataset for each cross-validation\n",
      "fold. So far we have only used [HalfPartitioner](http://pymvpa.org/generated/mvpa2.generators.partition.HalfPartitioner.html#mvpa2-generators-partition-halfpartitioner) to\n",
      "divide the dataset into odd and even runs (based on our custom sample\n",
      "attribute `runtype`). However, in general it is more common to perform so\n",
      "called leave-one-out cross-validation, where *one* independent part of a\n",
      "dataset is selected as testing dataset, while the other parts constitute the\n",
      "training dataset. This procedure is repeated till all parts have served as\n",
      "the testing dataset once. In case of our dataset we could consider each of\n",
      "the 12 runs as independent measurements (fMRI data doesn't allow us to\n",
      "consider temporally adjacent data to be considered independent).\n",
      "\n",
      "To run such an analysis, we first need to redo our dataset preprocessing,\n",
      "as, in the current one, we only have one sample per stimulus category for\n",
      "both odd and even runs. To get a dataset with one sample per stimulus\n",
      "category for each run, we need to modify the averaging step. Using what we\n",
      "have learned from the *last tutorial part* the\n",
      "following code snippet should be plausible:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datapath = os.path.join(tutorial_data_path, 'haxby2001')\n",
      "ds = load_tutorial_data(roi='vt')\n",
      "poly_detrend(ds, polyord=1, chunks_attr='chunks')\n",
      "zscore(ds, param_est=('targets', ['rest']))\n",
      "ds = ds[ds.sa.targets != 'rest']\n",
      "run_averager = mean_group_sample(['targets', 'chunks'])\n",
      "ds = ds.get_mapped(run_averager)\n",
      "ds.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 81,
       "text": [
        "(96, 577)"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Instead of two samples per category in the whole dataset, now we have one\n",
      "sample per category, per experiment run, hence 96 samples in the whole\n",
      "dataset. To set up a 12-fold leave-one-run-out cross-validation, we can\n",
      "make use of [NFoldPartitioner](http://pymvpa.org/generated/mvpa2.generators.partition.NFoldPartitioner.html#mvpa2-generators-partition-nfoldpartitioner). By default it is\n",
      "going to select samples from one `chunk` at a time:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cvte = CrossValidation(clf, NFoldPartitioner(),\n",
      "                       errorfx=lambda p, t: np.mean(p == t))\n",
      "cv_results = cvte(ds)\n",
      "np.mean(cv_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 82,
       "text": [
        "0.78125"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "We get almost the same prediction accuracy (reusing the SVM classifier and\n",
      "our custom error function). Note that this time we performed the analysis on\n",
      "a lot more samples that were each was computed from just a few fMRI volumes\n",
      "(about nine each).\n",
      "\n",
      "So far we have just looked at the mean accuracy or error. Let's investigate\n",
      "the results of the cross-validation analysis a bit further."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(cv_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 83,
       "text": [
        "mvpa2.datasets.base.Dataset"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print cv_results.samples"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.75 ]\n",
        " [ 0.875]\n",
        " [ 1.   ]\n",
        " [ 0.75 ]\n",
        " [ 0.75 ]\n",
        " [ 0.875]\n",
        " [ 0.75 ]\n",
        " [ 0.875]\n",
        " [ 0.75 ]\n",
        " [ 0.375]\n",
        " [ 1.   ]\n",
        " [ 0.625]]\n"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "The returned value is actually a [Dataset](http://pymvpa.org/generated/mvpa2.datasets.base.Dataset.html#mvpa2-datasets-base-dataset) with the\n",
      "results for all cross-validation folds. Since our error function computes\n",
      "only a single scalar value for each fold the dataset only contains a single\n",
      "feature (in this case the accuracy), and a sample per each fold."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "We Need To Take A Closer Look"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "By now we have already done a few cross-validation analyses using two\n",
      "different classifiers and different pre-processing strategies. In all these\n",
      "cases we have just looked at the generalization performance or error.\n",
      "However, error rates hide a lot of interesting information that is very\n",
      "important for an interpretation of results. In our case we analyzed a\n",
      "dataset with eight different categories. An average misclassification rate\n",
      "doesn't tell us much about the contribution of each category to the\n",
      "prediction error. It could be that *half of the samples of each category*\n",
      "get misclassified, but the same average error might be due to *all samples\n",
      "from half of the categories* being completely misclassified, while\n",
      "prediction accuracy for samples from the remaining categories is perfect.\n",
      "These two results would have to be interpreted in totally different ways,\n",
      "despite the same average error rate.\n",
      "\n",
      "In psychological research this type of results is usually presented as a\n",
      "[contingency table](http://en.wikipedia.org/wiki/Contingency_table) or [cross tabulation](http://en.wikipedia.org/wiki/Cross_tabulation) of expected vs. empirical\n",
      "results. [Signal detection theory](http://en.wikipedia.org/wiki/Detection_theory) offers a whole range of techniques to\n",
      "characterize such results. From this angle a\n",
      "classification analysis is hardly any different from a psychological\n",
      "experiment where a human observer performs a detection task, hence the same\n",
      "analysis procedures can be applied here as well.\n",
      "\n",
      "PyMVPA provides convenient access to [confusion matrices <confusion](http://pymvpa.org/glossary.html#term-confusion-matrices-<confusion), i.e.  contingency tables of targets vs. actual predictions.  However,\n",
      "to prevent wasting CPU-time and memory they are not computed by default, but\n",
      "instead have to be enabled explicitly. Optional analysis results like this are\n",
      "available in a dedicated collection of [conditional attribute](http://pymvpa.org/glossary.html#term-conditional-attribute)s --\n",
      "analogous to `sa` and `fa` in datasets, it is named `ca`. Let's see how\n",
      "it works:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cvte = CrossValidation(clf, NFoldPartitioner(),\n",
      "                       errorfx=lambda p, t: np.mean(p == t),\n",
      "                       enable_ca=['stats'])\n",
      "cv_results = cvte(ds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Via the `enable_ca` argument we triggered computing confusion tables for\n",
      "all cross-validation folds, but otherwise there is no change in the code.\n",
      "Afterwards the aggregated confusion for the whole cross-validation\n",
      "procedure is available in the `ca` collection. Let's take a look (note\n",
      "that in the printed manual the output is truncated due to page-width\n",
      "constraints -- please refer to the HTML-based version full the full matrix)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print cvte.ca.stats.as_string(description=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "----------.\n",
        "predictions\\targets     bottle         cat          chair          face         house        scissors    scrambledpix      shoe\n",
        "            `------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------ P'   N'   FP   FN   PPV  NPV  TPR  SPC  FDR  MCC  F1\n",
        "       bottle             6             0             3             0             0             5             0             1       15   75    9    6   0.4 0.92  0.5 0.88  0.6 0.34 0.44\n",
        "        cat               0             10            0             0             0             0             0             0       10   67    0    2    1  0.97 0.83   1    0  0.79 0.91\n",
        "       chair              0             0             7             0             0             0             0             0        7   73    0    5    1  0.93 0.58   1    0  0.66 0.74\n",
        "        face              0             2             0             12            0             0             0             0       14   63    2    0  0.86   1    1  0.97 0.14  0.8 0.92\n",
        "       house              0             0             0             0             12            0             0             0       12   63    0    0    1    1    1    1    0  0.87   1\n",
        "      scissors            2             0             1             0             0             6             0             0        9   75    3    6  0.67 0.92  0.5 0.96 0.33 0.48 0.57\n",
        "    scrambledpix          2             0             1             0             0             0             12            1       16   63    4    0  0.75   1    1  0.94 0.25 0.75 0.86\n",
        "        shoe              2             0             0             0             0             1             0             10      13   67    3    2  0.77 0.97 0.83 0.96 0.23 0.69  0.8\n",
        "Per target:          ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------\n",
        "         P                12            12            12            12            12            12            12            12\n",
        "         N                84            84            84            84            84            84            84            84\n",
        "         TP               6             10            7             12            12            6             12            10\n",
        "         TN               69            65            68            63            63            69            63            65\n",
        "Summary \\ Means:     ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------ 12 68.25 2.62 2.62 0.81 0.96 0.78 0.96 0.19 0.67 0.78\n",
        "       CHI^2            442.67       p=2e-58\n",
        "        ACC              0.78\n",
        "        ACC%            78.12\n",
        "     # of sets            12       ACC(i) = 0.87-0.015*i p=0.3 r=-0.33 r^2=0.11\n",
        "\n",
        "Statistics computed in 1-vs-rest fashion per each target.\n",
        "Abbreviations (for details see http://en.wikipedia.org/wiki/ROC_curve):\n",
        " TP : true positive (AKA hit)\n",
        " TN : true negative (AKA correct rejection)\n",
        " FP : false positive (AKA false alarm, Type I error)\n",
        " FN : false negative (AKA miss, Type II error)\n",
        " TPR: true positive rate (AKA hit rate, recall, sensitivity)\n",
        "      TPR = TP / P = TP / (TP + FN)\n",
        " FPR: false positive rate (AKA false alarm rate, fall-out)\n",
        "      FPR = FP / N = FP / (FP + TN)\n",
        " ACC: accuracy\n",
        "      ACC = (TP + TN) / (P + N)\n",
        " SPC: specificity\n",
        "      SPC = TN / (FP + TN) = 1 - FPR\n",
        " PPV: positive predictive value (AKA precision)\n",
        "      PPV = TP / (TP + FP)\n",
        " NPV: negative predictive value\n",
        "      NPV = TN / (TN + FN)\n",
        " FDR: false discovery rate\n",
        "      FDR = FP / (FP + TP)\n",
        " MCC: Matthews Correlation Coefficient\n",
        "      MCC = (TP*TN - FP*FN)/sqrt(P N P' N')\n",
        " F1 : F1 score\n",
        "      F1 = 2TP / (P + P') = 2TP / (2TP + FP + FN)\n",
        " AUC: Area under (AUC) curve\n",
        " CHI^2: Chi-square of confusion matrix\n",
        " LOE(ACC): Linear Order Effect in ACC across sets\n",
        " # of sets: number of target/prediction sets which were provided\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "This output is a comprehensive summary of the performed analysis. We can\n",
      "see that the confusion matrix has a strong diagonal, and confusion happens\n",
      "mostly among small objects. In addition to the plain contingency table\n",
      "there are also a number of useful summary statistics readily available --\n",
      "including average accuracy.\n",
      "\n",
      "Especially for multi-class datasets the matrix quickly becomes\n",
      "incomprehensible. For these cases the confusion matrix can also be plotted\n",
      "via its [plot()](http://pymvpa.org/generated/mvpa2.clfs.transerror.ConfusionMatrix.plot.html#mvpa2-clfs-transerror-confusionmatrix-plot) method. If the\n",
      "confusions shall be used as input for further processing they can also be\n",
      "accessed in pure matrix format:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cvte.ca.stats.plot(labels=['face','cat','shoe','bottle','scissors','chair','house','scrambledpix'], numbers=True, numbers_alpha=1.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 110,
       "text": [
        "(<matplotlib.figure.Figure at 0x7fbfa703a350>,\n",
        " <matplotlib.image.AxesImage at 0x7fbfa6715610>,\n",
        " <matplotlib.colorbar.Colorbar instance at 0x7fbfa65dd200>)"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEyCAYAAAD5tWvWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRwAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7fbfa703a350>"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cvte.ca.stats.plot?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cvte.ca.stats.matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 100,
       "text": [
        "array([[ 6,  0,  3,  0,  0,  5,  0,  1],\n",
        "       [ 0, 10,  0,  0,  0,  0,  0,  0],\n",
        "       [ 0,  0,  7,  0,  0,  0,  0,  0],\n",
        "       [ 0,  2,  0, 12,  0,  0,  0,  0],\n",
        "       [ 0,  0,  0,  0, 12,  0,  0,  0],\n",
        "       [ 2,  0,  1,  0,  0,  6,  0,  0],\n",
        "       [ 2,  0,  1,  0,  0,  0, 12,  1],\n",
        "       [ 2,  0,  0,  0,  0,  1,  0, 10]])"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "The classifier confusions are just an example of the general mechanism of\n",
      "conditional attribute that is supported by many objects in PyMVPA."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}